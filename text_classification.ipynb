{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text (News) Classification with Pytorch and Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ag_news_csv.tar.gz: 11.8MB [00:00, 13.4MB/s]\n",
      "120000lines [00:07, 15367.60lines/s]\n",
      "120000lines [00:13, 8695.06lines/s]\n",
      "7600lines [00:00, 8646.11lines/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext.datasets import text_classification\n",
    "NGRAMS = 2\n",
    "import os\n",
    "if not os.path.isdir('news_data'):\n",
    "    os.mkdir('news_data')\n",
    "train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](\n",
    "    root='news_data', ngrams=NGRAMS, vocab=None)\n",
    "BATCH_SIZE = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class TextSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
    "EMBED_DIM = 32\n",
    "NUN_CLASS = len(train_dataset.get_labels())\n",
    "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    label = torch.tensor([entry[0] for entry in batch])\n",
    "    text = [entry[1] for entry in batch]\n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    # torch.Tensor.cumsum returns the cumulative sum\n",
    "    # of elements in the dimension dim.\n",
    "    # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0)\n",
    "\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text = torch.cat(text)\n",
    "    return text, offsets, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_func(sub_train_):\n",
    "\n",
    "    # Train the model\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      collate_fn=generate_batch)\n",
    "    for i, (text, offsets, cls) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        output = model(text, offsets)\n",
    "        loss = criterion(output, cls)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    return train_loss / len(sub_train_), train_acc / len(sub_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "    for text, offsets, cls in data:\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(text, offsets)\n",
    "            loss = criterion(output, cls)\n",
    "            loss += loss.item()\n",
    "            acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    return loss / len(data_), acc / len(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  | time in 0 minutes, 24 seconds\n",
      "\tLoss: 0.0262(train)\t|\tAcc: 84.7%(train)\n",
      "\tLoss: 0.0001(valid)\t|\tAcc: 90.6%(valid)\n",
      "Epoch: 2  | time in 0 minutes, 24 seconds\n",
      "\tLoss: 0.0119(train)\t|\tAcc: 93.7%(train)\n",
      "\tLoss: 0.0002(valid)\t|\tAcc: 90.8%(valid)\n",
      "Epoch: 3  | time in 0 minutes, 24 seconds\n",
      "\tLoss: 0.0070(train)\t|\tAcc: 96.3%(train)\n",
      "\tLoss: 0.0002(valid)\t|\tAcc: 90.8%(valid)\n",
      "Epoch: 4  | time in 0 minutes, 23 seconds\n",
      "\tLoss: 0.0039(train)\t|\tAcc: 98.0%(train)\n",
      "\tLoss: 0.0002(valid)\t|\tAcc: 91.0%(valid)\n",
      "Epoch: 5  | time in 0 minutes, 23 seconds\n",
      "\tLoss: 0.0023(train)\t|\tAcc: 99.0%(train)\n",
      "\tLoss: 0.0002(valid)\t|\tAcc: 91.2%(valid)\n",
      "Epoch: 6  | time in 0 minutes, 23 seconds\n",
      "\tLoss: 0.0015(train)\t|\tAcc: 99.4%(train)\n",
      "\tLoss: 0.0002(valid)\t|\tAcc: 91.3%(valid)\n",
      "Epoch: 7  | time in 0 minutes, 24 seconds\n",
      "\tLoss: 0.0011(train)\t|\tAcc: 99.6%(train)\n",
      "\tLoss: 0.0002(valid)\t|\tAcc: 91.4%(valid)\n",
      "Epoch: 8  | time in 0 minutes, 23 seconds\n",
      "\tLoss: 0.0008(train)\t|\tAcc: 99.7%(train)\n",
      "\tLoss: 0.0002(valid)\t|\tAcc: 91.2%(valid)\n",
      "Epoch: 9  | time in 0 minutes, 23 seconds\n",
      "\tLoss: 0.0006(train)\t|\tAcc: 99.8%(train)\n",
      "\tLoss: 0.0002(valid)\t|\tAcc: 91.3%(valid)\n",
      "Epoch: 10  | time in 0 minutes, 24 seconds\n",
      "\tLoss: 0.0005(train)\t|\tAcc: 99.8%(train)\n",
      "\tLoss: 0.0002(valid)\t|\tAcc: 91.2%(valid)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.data.dataset import random_split\n",
    "N_EPOCHS = 10\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "train_len = int(len(train_dataset) * 0.95)\n",
    "sub_train_, sub_valid_ = \\\n",
    "    random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(sub_train_)\n",
    "    valid_loss, valid_acc = test(sub_valid_)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset...\n",
      "\tLoss: 0.0002(test)\t|\tAcc: 90.0%(test)\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset...')\n",
    "test_loss, test_acc = test(test_dataset)\n",
    "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from torchtext.data.utils import ngrams_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "ag_news_label = {1 : \"World\",\n",
    "                 2 : \"Sports\",\n",
    "                 3 : \"Business\",\n",
    "                 4 : \"Sci/Tec\"}\n",
    "\n",
    "def predict(text, model, vocab, ngrams):\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor([vocab[token]\n",
    "                            for token in ngrams_iterator(tokenizer(text), ngrams)])\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "vocab = train_dataset.get_vocab()\n",
    "model = model.to(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Sci/Tec news\n"
     ]
    }
   ],
   "source": [
    "text = \"A horror version of Fantasy Island, frankly, sounds more interesting than a \\\n",
    "        conventional reboot, which explains why Sony would hand the keys to Blumhouse, \\\n",
    "        the reigning maestro of that genre, and let them run with it. \\\n",
    "        That seed of potential, however, sails away on a tide of numbing stupidity. \\\n",
    "        A frantic woman races through the jungle as the movie begins, serving notice \\\n",
    "        that this isn't grandma's Fantasy Island, the escapist TV show that premiered in 1978. \\\n",
    "        That tease is followed by more familiar images, as a handful of contest winners \\\n",
    "        land on an idyllic island (played by Fiji, incidentally), before being ushered in \\\n",
    "        to meet their host, the mysterious Mr. Roarke (Michael Pena), who walks them through the rules. \\\n",
    "        Their fantasy, he explains, will be as real as you make it, in a locale where anything and \\\n",
    "        everything is possible. But they must see each experience through to its conclusion, setting \\\n",
    "        them on disparate adventures, which -- barring the odd moment of creepiness -- \\\n",
    "        start promisingly enough, before becoming increasingly fantastic and eventually, deadly. \\\n",
    "        The movie exhibits promise at first too, if only because it's hard to anticipate \\\n",
    "        where all this is going, in a The Twilight Zone kind of way. The lesson appears to \\\n",
    "        involve being careful what you wish for -- a tried-and-true wrinkle of such fare. \\\n",
    "        Gwen (Maggie Q), for example, has the chance to undo a choice that took her life in \\\n",
    "        a completely different direction, while Melanie (Lucy Hale) plots sweet revenge  \\\n",
    "        against a woman (Mr. Robot's Portia Doubleday) who tormented her in school. \\\n",
    "        Lucy Hale, Austin Stowell and Michael Peña in 'Fantasy Island.'\\\n",
    "        Gradually, though, the situations conjured courtesy of director/co-writer \\\n",
    "        Jeff Wadlow (Blumhouse's Truth or Dare) become more and more outlandish, and make \\\n",
    "        less and less sense. By the time an inkling of what's going on comes into focus, \\\n",
    "        any reasonable person would have long since asked where and when they can claim their \\\n",
    "        luggage and disembark.\\\n",
    "        It's a shame, since the general idea of taking creative liberties with such a title -- \\\n",
    "        one with which the target audience probably identifies by name only -- sounds fertile. \\\n",
    "        While there are amusing if somewhat obvious callbacks to the original (yes, someone yells \\\n",
    "        The plane!), the assumption is clearly that the demo most likely to see the movie \\\n",
    "        couldn't pick Ricardo Montalban out of a lineup.\\\n",
    "        Blumhouse -- whose hits include Get Out and Happy Death Day -- has been extraordinarily\\\n",
    "        shrewd about mining and stretching the parameters of horror, as well as leveraging familiar\\\n",
    "        concepts in different ways. (The studio will put its stamp on another well-worn \\\n",
    "        premise next month, with a new version of The Invisible Man.)\\\n",
    "        For the squeamish, it's somewhat reassuring to note that Fantasy Island delivers\\\n",
    "        PG-13-level scares, so the action isn't particularly grisly, just awfully silly.\\\n",
    "        Granted, one person's fantasy can easily be another's nightmare, but in this case,\\\n",
    "        the likely effect on an even moderately discriminating viewer will merely be a \\\n",
    "        nagging headache. The bottom line is that visiting Fantasy Island -- even on \\\n",
    "        someone else's dime -- isn't a trip worth taking.\"\n",
    "\n",
    "print(\"This is a %s news\" %ag_news_label[predict(text, model, vocab, 2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth is Politics\n",
      "The predicted category is Sports news\n"
     ]
    }
   ],
   "source": [
    "text1 = \"The Army will not investigate Lt. Col. Alexander Vindman, the former \\\n",
    "        National Security Council staffer who testified in the president’s \\\n",
    "        impeachment investigation, the service’s top civilian said Friday.\\\n",
    "        Army Secretary Ryan McCarthy made the announcement at an event just \\\n",
    "        days after President Donald Trump said he imagined the military would \\\n",
    "        take a look at whether Vindman should face disciplinary action for the \\\n",
    "        horrible things he told House investigators about the president’s \\\n",
    "        phone call with Ukrainian President Volodymyr Zelensky last July.\\\n",
    "        Vindman was ousted from his position on the NSC last week after the \\\n",
    "        Senate acquitted Trump. Vindman’s lawyer said the move amounted to retribution.\\\n",
    "        McCarthy on Friday downplayed Vindman’s return to the Army, saying he simply \\\n",
    "        returned to the service a few months earlier than planned and would have a \\\n",
    "        bridging assignment for a couple of months in the Army’s headquarters office in Washington.\\\n",
    "        Then he will be heading to a senior service college this summer. \\\n",
    "        There’s no investigation into him, McCarthy said at a National Press Club luncheon.\\\n",
    "        On Tuesday, Trump told reporters if you look at what happened, \\\n",
    "        [the military is] going to certainly, I would imagine, take a look at that.\\\n",
    "        It turned out that what he reported was very different [than what occurred], \\\n",
    "        Trump added. And also when you look at the person he reports to, said horrible \\\n",
    "        things, avoided the chain of command, leaked, did a lot of bad things. \\\n",
    "        And so we sent him on his way to a much different location, and the military \\\n",
    "        can handle him anyway they want.\"\n",
    "\n",
    "print(\"The ground truth is Politics\")\n",
    "print(\"The predicted category is %s news\" %ag_news_label[predict(text1, model, vocab, 2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth is Science\n",
      "The predicted category is Sci/Tec news\n"
     ]
    }
   ],
   "source": [
    "text2 = \"Cramped in a small submarine 2,500 meters below the Pacific’s surface in 2006, \\\n",
    "        microbiologist Hiroyuki Imachi scanned the ocean floor for signs of microbial life.\\\n",
    "        As the sub drifted over the bottom of Japan’s Nankai Trough — a hotbed of \\\n",
    "        understudied microbes living off methane bubbling up from tectonic faults — \\\n",
    "        Imachi spotted a nest of small clams against a whitish microbial mat, \\\n",
    "        suggestive of an active methane seep below. The submersible’s robotic \\\n",
    "        arm plunged a 25-centimeter tube into the blackish-gray sediment to retrieve a core of muck.\\\n",
    "        It would take another 12 years of lab work for Imachi and colleagues \\\n",
    "        to isolate a prize they hadn’t even set out to find — a single-celled \\\n",
    "        microbe from an ancient lineage of Archaea, a domain of life \\\n",
    "        superficially similar to bacteria. That find could help biologists \\\n",
    "        reconstruct one of life’s greatest leaps toward complexity, from \\\n",
    "        simple bacteria-like organisms to more complicated eukaryotes, \\\n",
    "        the enormous group of chromosome-carrying creatures that includes \\\n",
    "        humans, platypuses, fungi and many others.  \\\n",
    "        Patience is very important in doing successful science, says Imachi, \\\n",
    "        of the Japan Agency for Marine-Earth Science and Technology in Yokosuka. \\\n",
    "        He and his colleagues published their findings in the Jan. \\\n",
    "        23 Nature, to enthusiastic acclaim from fellow microbiologists. \\\n",
    "        I’m very lucky. The Japanese research vessel Shinkai 6500 dove \\\n",
    "        2,500 meters into the Nankai Trough off of Japan’s Kii peninsula \\\n",
    "        to sample the microbial diversity in the sediment around a methane seep in 2006. \\\n",
    "        Many scientists think an unusual meal kicked off the evolution of more complicated \\\n",
    "        cells about 2 billion years ago. An ancient archaean, the theory goes, \\\n",
    "        gobbled up a bacterium that, instead of being dinner, sparked a symbiotic \\\n",
    "        relationship in a process called endosymbiosis (SN: 6/8/74). Eventually, \\\n",
    "        the bacterium evolved into mitochondria, the energy-producing cellular \\\n",
    "        structures that fueled the rise of complex life.\\\n",
    "        Living remnants of ancient archaeal lineages persist in some of Earth’s \\\n",
    "        most extreme environments, and scientists are exploring these microbial \\\n",
    "        hot spots for clues about the ancestor of all eukaryotes. \\\n",
    "        One such environment is the deep-sea floor. Despite making up about \\\n",
    "        65 percent of Earth’s surface, biologists have only a faint picture \\\n",
    "        of the microbial multitudes that thrive there. Genetic sequencing of \\\n",
    "        dredged up mud has given biologists one way of studying these communities \\\n",
    "        of bacteria and archaea uniquely adapted to the cold, oxygen-less deep. \\\n",
    "        But genes can reveal only so much.So scientists seek to grow cultures of \\\n",
    "        microbes in the lab to study what these organisms look like and how they behave. \\\n",
    "        But extreme microbes present unique challenges. Simply plating these organisms \\\n",
    "        on a petri dish, providing nutrients and waiting for growth hadn’t ever worked — \\\n",
    "        possibly because scientists weren’t effectively re-creating the microbes’ extreme \\\n",
    "        environment, says Masaru Nobu, a microbiologist at the National Institute of \\\n",
    "        Advanced Industrial Science and Technology in Tsukuba, Japan, who joined Imachi’s \\\n",
    "        project after it started. So Imachi, Nobu and their colleagues tried to \\\n",
    "        re-create a methane seep in the lab, drawing inspiration from a bioreactor \\\n",
    "        used to treat municipal sewage. The team pumped methane gas into a meter-tall \\\n",
    "        cylindrical chamber, kept at 10° Celsius and stacked with polyurethane sponges \\\n",
    "        that mimic porous deep-sea sediment. A slow, steady flow of artificial seawater \\\n",
    "        kept the sponges saturated. The team then watered down a clump of mud from the \\\n",
    "        Nankai Trough sediment core, sopped up the slurry with the sponges, stacked them \\\n",
    "        in the reactor — and waited. There was a lot of nervousness, Nobu says of that \\\n",
    "        time in December 2006. “We didn’t know if we’d get what we wanted. \\\n",
    "        Cramped in a small submarine 2,500 meters below the Pacific’s surface in 2006, \\\n",
    "        microbiologist Hiroyuki Imachi scanned the ocean floor for signs of microbial life. \\\n",
    "        As the sub drifted over the bottom of Japan’s Nankai Trough — a hotbed of \\\n",
    "        understudied microbes living off methane bubbling up from tectonic faults — \\\n",
    "        Imachi spotted a nest of small clams against a whitish microbial mat, \\\n",
    "        suggestive of an active methane seep below. The submersible’s robotic arm \\\n",
    "        plunged a 25-centimeter tube into the blackish-gray sediment to retrieve a core of muck.\\\n",
    "        It would take another 12 years of lab work for Imachi and colleagues to isolate a \\\n",
    "        prize they hadn’t even set out to find — a single-celled microbe from an ancient \\\n",
    "        lineage of Archaea, a domain of life superficially similar to bacteria. \\\n",
    "        That find could help biologists reconstruct one of life’s greatest leaps \\\n",
    "        toward complexity, from simple bacteria-like organisms to more complicated \\\n",
    "        eukaryotes, the enormous group of chromosome-carrying creatures that includes \\\n",
    "        humans, platypuses, fungi and many others.  \\\n",
    "        Patience is very important in doing successful science, says Imachi, of \\\n",
    "        the Japan Agency for Marine-Earth Science and Technology in Yokosuka. \\\n",
    "        He and his colleagues published their findings in the Jan. 23 Nature, \\\n",
    "        to enthusiastic acclaim from fellow microbiologists. “I’m very lucky.\"\n",
    "\n",
    "print(\"The ground truth is Science\")\n",
    "print(\"The predicted category is %s news\" %ag_news_label[predict(text2, model, vocab, 2)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
